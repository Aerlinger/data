{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Github\n",
    "https://github.com/CSSEGISandData/COVID-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "--2020-03-14 18:18:23--  https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443...connected.\nHTTP request sent, awaiting response...200 OK\nLength: 60607 (59K) [text/plain]\nSaving to: ‘time_series_19-covid-Recovered.csv’\n\ntime_series_19-covi 100%[===================>]  59.19K  --.-KB/s    in 0.04s   \n\n2020-03-14 18:18:23 (1.60 MB/s) - ‘time_series_19-covid-Recovered.csv’ saved [60607/60607]\n\n--2020-03-14 18:18:23--  https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443...connected.\nHTTP request sent, awaiting response...200 OK\nLength: 58635 (57K) [text/plain]\nSaving to: ‘time_series_19-covid-Deaths.csv’\n\ntime_series_19-covi 100%[===================>]  57.26K  --.-KB/s    in 0.03s   \n\n2020-03-14 18:18:24 (1.72 MB/s) - ‘time_series_19-covid-Deaths.csv’ saved [58635/58635]\n\n--2020-03-14 18:18:24--  https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443...connected.\nHTTP request sent, awaiting response...200 OK\nLength: 62628 (61K) [text/plain]\nSaving to: ‘time_series_19-covid-Confirmed.csv’\n\ntime_series_19-covi 100%[===================>]  61.16K  --.-KB/s    in 0.04s   \n\n2020-03-14 18:18:24 (1.70 MB/s) - ‘time_series_19-covid-Confirmed.csv’ saved [62628/62628]\n\n"
    }
   ],
   "source": [
    "!rm time_series_19-covid-*.csv\n",
    "!wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv\n",
    "!wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv\n",
    "!wget https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Latest data found from 1/22/20 to 3/13/20\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CONFIRMED = pd.read_csv('time_series_19-covid-Confirmed.csv')\n",
    "RECOVERED = pd.read_csv('time_series_19-covid-Recovered.csv')\n",
    "DEATHS = pd.read_csv('time_series_19-covid-Deaths.csv')\n",
    "\n",
    "DEL_COLS = ['Province/State', 'Country/Region', 'Lat', 'Long']\n",
    "DATE_RANGE = [col for col in CONFIRMED.columns if col not in DEL_COLS]\n",
    "print('Latest data found from %s to %s' % (DATE_RANGE[0], DATE_RANGE[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a map for country ISO codes\n",
    "Data from https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Countries with ISO codes found: 125\n"
    }
   ],
   "source": [
    "# Convert country names to ISO codes\n",
    "ISO_CODES = pd.read_csv('country_iso_codes.csv').set_index('ISO 3166')\n",
    "\n",
    "# Pre-seed the ISO map with problematic labels\n",
    "COUNTRY_ISO_MAP = {\n",
    "    'US': 'US',\n",
    "    'Brunei': 'BN',\n",
    "    'United Kingdom': 'UK',\n",
    "    'Cruise Ship': '??',\n",
    "    'Reunion': 'RE',\n",
    "    'Taiwan*': 'TW',\n",
    "    'Russia': 'RU',\n",
    "    'Cote d\\'Ivoire': 'CI',\n",
    "    'Congo (Kinshasa)': 'CD',\n",
    "    'Korea, South': 'KR',\n",
    "}\n",
    "\n",
    "for country in CONFIRMED['Country/Region'].unique():\n",
    "    if country in COUNTRY_ISO_MAP:\n",
    "        continue\n",
    "    elif country not in ISO_CODES.index:\n",
    "        raise ValueError('Needs correction: %s' % country)\n",
    "    else:\n",
    "        COUNTRY_ISO_MAP[country] = ISO_CODES.loc[country]['ISO 3166-1-2']\n",
    "        \n",
    "print('Countries with ISO codes found: %d' % len(COUNTRY_ISO_MAP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a map for region codes (USA, Canada and Australia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION_CODES = pd.read_csv('country_region_codes.csv')\n",
    "\n",
    "REGION_MAP = {}\n",
    "for idx, row in REGION_CODES.iterrows():\n",
    "    REGION_MAP[row['Name']] = row['Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data from Johns Hopkins into time series format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "# Root path of the project\n",
    "ROOT = Path('..')\n",
    "\n",
    "# Create constants\n",
    "REGION_COLUMN = 'Province/State'\n",
    "COUNTRY_COLUMN = 'Country/Region'\n",
    "CONFIRMED_EVENT = 'Confirmed'\n",
    "RECOVERED_EVENT = 'Recovered'\n",
    "DEATH_EVENT = 'Deaths'\n",
    "\n",
    "def get_event(df: pd.DataFrame):\n",
    "    ''' Helper function used to derive event from dataframe instance '''\n",
    "    if df.equals(CONFIRMED): return CONFIRMED_EVENT\n",
    "    if df.equals(RECOVERED): return RECOVERED_EVENT\n",
    "    if df.equals(DEATHS): return DEATH_EVENT\n",
    "    raise ValueError('Unknown')\n",
    "    \n",
    "def parse_date(datestr: str):\n",
    "    return datetime.datetime.strptime(datestr, '%m/%d/%y')\n",
    "\n",
    "region_country_pairs = CONFIRMED.fillna('').apply(\n",
    "    lambda row: (row[REGION_COLUMN], row[COUNTRY_COLUMN]), axis=1).unique()\n",
    "\n",
    "records = []\n",
    "for event, df in zip((CONFIRMED_EVENT, RECOVERED_EVENT, DEATH_EVENT), (CONFIRMED, RECOVERED, DEATHS)):\n",
    "    df = df.copy().fillna('')\n",
    "    \n",
    "    # Parse the country\n",
    "    df[COUNTRY_COLUMN] = df[COUNTRY_COLUMN].apply(lambda value: COUNTRY_ISO_MAP[value])\n",
    "\n",
    "    # Parse the region\n",
    "    df[REGION_COLUMN] = df[REGION_COLUMN].apply(lambda region: region.split(', ')[-1])\n",
    "    df[REGION_COLUMN] = df[REGION_COLUMN].apply(lambda region: REGION_MAP.get(region, region))\n",
    "    df[REGION_COLUMN] = df[REGION_COLUMN].apply(lambda region: 'DC' if region == 'D.C.' else region)\n",
    "    \n",
    "    # Collapse duplicate regions (e.g. counties)\n",
    "    # NOTE: this breaks lat/lon values\n",
    "    df = df.groupby(by=['Province/State', 'Country/Region']).sum().reset_index() \n",
    "\n",
    "    for idx, row in df.iterrows():        \n",
    "            \n",
    "        for date in DATE_RANGE:\n",
    "            records.append({\n",
    "                'Date': parse_date(date),\n",
    "                'Country': row[COUNTRY_COLUMN], \n",
    "                'Region': row[REGION_COLUMN],\n",
    "                'Event': event,\n",
    "                'Value': row[date]\n",
    "            })\n",
    "\n",
    "sort_order = ['Date', 'Country', 'Region', 'Event']\n",
    "ts = pd.DataFrame.from_records(records).sort_values(sort_order).set_index('Date', drop=True)\n",
    "ts.to_csv(ROOT / 'time_series.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}